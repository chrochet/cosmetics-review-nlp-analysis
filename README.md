# cosmetics-review-text-mining
ì›¹ ë¦¬ë·° ê¸°ë°˜ í™”ì¥í’ˆ ë§Œì¡±Â·ë¶ˆë§Œì¡± ìš”ì¸ íƒìƒ‰ 

---

## ğŸ–¥ï¸ í”„ë¡œì íŠ¸ ì†Œê°œ
ë³¸ í”„ë¡œì íŠ¸ëŠ” ì›¹ í˜ì´ì§€(í™”ì¥í’ˆ ë¦¬ë·°)ì˜ HTML ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œ ë’¤,  
í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ í‚¤ì›Œë“œ ë¶„ì„(TF-IDF)ê³¼ í† í”½ ëª¨ë¸ë§(LDA)ì„ ìˆ˜í–‰í•˜ì—¬  
ë¦¬ë·°ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì£¼ìš” ë§Œì¡±/ë¶ˆë§Œì¡± ìš”ì¸ì„ íƒìƒ‰í•˜ëŠ” í…ìŠ¤íŠ¸ ë§ˆì´ë‹ í”„ë¡œì íŠ¸ì´ë‹¤.

---

## ğŸ•°ï¸ ê°œë°œ ê¸°ê°„
2024.11.23- 2025.02.04

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ ë©¤ë²„ êµ¬ì„±
- ê°œì¸ í”„ë¡œì íŠ¸

---

## ğŸ§© ì—°êµ¬ / ì‹œìŠ¤í…œ êµ¬ì¡° (Workflow)
### 01. ì›¹ ë°ì´í„° ìˆ˜ì§‘ (HTML Scraping)
- Selenium ê¸°ë°˜ìœ¼ë¡œ ì›¹ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ë¡œë”© ì²˜ë¦¬
- BeautifulSoupë¡œ HTML íŒŒì‹± í›„ ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ
- ìˆ˜ì§‘ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì €ì¥(CSV)

### 02. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ì œ
- ê²°ì¸¡/ì¤‘ë³µ ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì •ê·œí™”
- íŠ¹ìˆ˜ë¬¸ì/ì´ëª¨ì§€ ì œê±°
- KoNLPy(Okt) ê¸°ë°˜ í˜•íƒœì†Œ ë¶„ì„ ë° í† í°í™”
- ë¶ˆìš©ì–´ ì œê±° ë° ë¶„ì„ìš© í† í° ë°ì´í„° ìƒì„±

### 03. í‚¤ì›Œë“œ ë¶„ì„ (TF-IDF)
- ê²°ì¸¡ê°’ ì œê±° í›„ ë°ì´í„° ì •ë¦¬
- TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ì¤‘ìš”ë„ ì‚°ì¶œ
- ìƒìœ„ í‚¤ì›Œë“œ ë„ì¶œë¡œ í•µì‹¬ ì–¸ê¸‰ ìš”ì†Œ íƒìƒ‰

### 04. í† í”½ ëª¨ë¸ë§ (LDA)
- ì „ì²˜ë¦¬ëœ í† í° ë°ì´í„° ê¸°ë°˜ LDA í•™ìŠµ
- í† í”½ë³„ í•µì‹¬ ë‹¨ì–´ í™•ì¸
- í† í”½ ì‘ì§‘ë„(Coherence) í‰ê°€ë¥¼ í†µí•´ í† í”½ í’ˆì§ˆ í™•ì¸

---

## âš™ï¸ ê°œë°œ í™˜ê²½
- **Language**: Python
- **Scraping**: Selenium, BeautifulSoup4
- **Preprocessing/NLP**: pandas, numpy, re, KoNLPy(Okt)
- **Keyword Analysis**: scikit-learn (TF-IDF)
- **Topic Modeling**: gensim (LDA, CoherenceModel)
- **Visualization**: matplotlib

---

## ğŸ“Œ ì£¼ìš” ê¸°ëŠ¥
### 01 ì›¹í˜ì´ì§€ HTML ìˆ˜ì§‘ ë° ë¦¬ë·° ì¶”ì¶œ
- Selenium ê¸°ë°˜ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì²˜ë¦¬
- BeautifulSoup HTML íŒŒì‹±ìœ¼ë¡œ ë¦¬ë·° í…ìŠ¤íŠ¸ ìˆ˜ì§‘
- CSV ì €ì¥

: `./ë¦¬ë“¤ìƒ· 300.ipynb`

---

### 02 ë°ì´í„° ì „ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì •ì œ  
- ê²°ì¸¡/ì¤‘ë³µ ì œê±°
- í…ìŠ¤íŠ¸ ì •ê·œí™”
- í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í† í°í™”(Okt)
- ë¶ˆìš©ì–´ ì œê±° ë° Token ë°ì´í„° ìƒì„±

:`./ì „ì²˜ë¦¬ 12.21 .ipynb`

---

### 03 TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ 
- ë¦¬ë·° í…ìŠ¤íŠ¸ ê²°ì¸¡ê°’ ì œê±° ë° ì •ë¦¬
- TF-IDFë¡œ í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ìš”ë„ ì‚°ì¶œ
- ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ

: `./tf-idf.ipynb`

---

### 04 LDA ê¸°ë°˜ í† í”½ ëª¨ë¸ë§
- í† í° ê¸°ë°˜ corpus/dictionary ìƒì„±
- LDA í† í”½ ëª¨ë¸ í•™ìŠµ
- Coherence Score í‰ê°€ë¡œ í† í”½ í’ˆì§ˆ í™•ì¸

: `./LDA .ipynb`







# ğŸ’» Code (Toggle)

## 01. HTML Scraping (ë¦¬ë“¤ìƒ· 300.ipynb)
<details>
<summary>ğŸ’» code | Selenium ìŠ¤í¬ë¡¤ ë¡œë”© + BeautifulSoup íŒŒì‹± + CSV ì €ì¥</summary>
<div markdown="1">

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
from bs4 import BeautifulSoup
import pandas as pd

driver = webdriver.Chrome()
url = "YOUR_URL_HERE"
driver.get(url)
time.sleep(3)

# âœ… ìŠ¤í¬ë¡¤ ë¡œë”© (ë¦¬ë·° ë” ë¶ˆëŸ¬ì˜¤ê¸°)
last_height = driver.execute_script("return document.body.scrollHeight")
for _ in range(15):
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)
    new_height = driver.execute_script("return document.body.scrollHeight")
    if new_height == last_height:
        break
    last_height = new_height

# âœ… HTML íŒŒì‹±
soup = BeautifulSoup(driver.page_source, "html.parser")

# âœ… ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (selectorëŠ” í˜ì´ì§€ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
reviews = []
for r in soup.select("YOUR_REVIEW_SELECTOR"):
    text = r.get_text(strip=True)
    if text:
        reviews.append(text)

driver.quit()

# âœ… DataFrame ì €ì¥
df = pd.DataFrame({"review": reviews})
df.to_csv("raw_reviews.csv", index=False, encoding="utf-8-sig")
print(f"Saved: {len(df)} reviews")
````

</div>
</details>

---

## 02. Text Preprocessing (ì „ì²˜ë¦¬ 12.21.ipynb)

<details>
<summary>ğŸ’» code | ì •ê·œì‹ ì •ì œ + ê²°ì¸¡/ì¤‘ë³µ ì œê±° + í˜•íƒœì†Œ ë¶„ì„(Okt) + ë¶ˆìš©ì–´ ì²˜ë¦¬</summary>
<div markdown="1">

```python
import pandas as pd
import re
from konlpy.tag import Okt

okt = Okt()

# âœ… ë°ì´í„° ë¡œë“œ
df = pd.read_csv("raw_reviews.csv")

# âœ… ê²°ì¸¡/ì¤‘ë³µ ì œê±°
df = df.dropna(subset=["review"])
df = df.drop_duplicates(subset=["review"])

# âœ… í…ìŠ¤íŠ¸ ì •ê·œí™” í•¨ìˆ˜
def clean_text(text: str) -> str:
    text = str(text)
    text = re.sub(r"http\S+|www\S+", "", text)                 # URL ì œê±°
    text = re.sub(r"[^ê°€-í£0-9a-zA-Z\s]", " ", text)            # íŠ¹ìˆ˜ë¬¸ì/ì´ëª¨ì§€ ì œê±°
    text = re.sub(r"\s+", " ", text).strip()                   # ê³µë°± ì •ë¦¬
    return text

df["clean_review"] = df["review"].apply(clean_text)

# âœ… ë¶ˆìš©ì–´(ì˜ˆì‹œ)
stopwords = set(["ì§„ì§œ", "ë„ˆë¬´", "ì™„ì „", "ê·¸ëƒ¥", "ì •ë§", "ì•½ê°„", "ê²ƒ", "ìˆ˜", "ë•Œ"])

# âœ… í˜•íƒœì†Œ ë¶„ì„ + í† í°í™”
def tokenize(text: str):
    tokens = okt.morphs(text, stem=True)
    tokens = [t for t in tokens if len(t) > 1 and t not in stopwords]
    return tokens

df["tokens"] = df["clean_review"].apply(tokenize)

# âœ… ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
df.to_csv("preprocessed_reviews.csv", index=False, encoding="utf-8-sig")
print("Saved: preprocessed_reviews.csv")
```

</div>
</details>

---

## 03. TF-IDF Keyword Extraction (tf-idf.ipynb)

<details>
<summary>ğŸ’» code | TF-IDF í•™ìŠµ + ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ</summary>
<div markdown="1">
<img width="641" height="411" alt="image" src="https://github.com/user-attachments/assets/8a3c5dc5-0c76-4298-a732-4f24d2f79f26" />

```python
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

df = pd.read_csv("preprocessed_reviews.csv")

# âœ… TF-IDFëŠ” ë¬¸ìì—´ ì…ë ¥ í•„ìš” â†’ í† í° join
# tokens ì»¬ëŸ¼ì´ ë¬¸ìì—´(list í˜•íƒœ)ë¡œ ì €ì¥ëœ ê²½ìš° evalë¡œ ë³€í™˜

def safe_join(x):
    if pd.isna(x):
        return ""
    if isinstance(x, str):
        try:
            return " ".join(eval(x))
        except:
            return x
    return " ".join(x)

df["text_for_tfidf"] = df["tokens"].apply(safe_join)

vectorizer = TfidfVectorizer(max_features=2000)
tfidf = vectorizer.fit_transform(df["text_for_tfidf"])

# âœ… ì „ì²´ ë¦¬ë·° ê¸°ì¤€ ìƒìœ„ í‚¤ì›Œë“œ
scores = tfidf.sum(axis=0).A1
keywords = vectorizer.get_feature_names_out()

top_n = 20
top_idx = scores.argsort()[::-1][:top_n]
top_keywords = [(keywords[i], round(scores[i], 3)) for i in top_idx]

print("Top TF-IDF Keywords")
for k, s in top_keywords:
    print(k, s)
```

</div>
</details>

---

## 04. LDA Topic Modeling (LDA.ipynb)

<details>
<summary>ğŸ’» code | Dictionary/Corpus ìƒì„± â†’ LDA í•™ìŠµ â†’ Coherence Score í‰ê°€</summary>
<div markdown="1">


<img width="499" height="162" alt="image" src="https://github.com/user-attachments/assets/54c6b795-e92a-4218-b6d2-db62beeef8b2" />

<img width="1500" height="219" alt="image" src="https://github.com/user-attachments/assets/5df73bd5-ef53-4b13-a7e5-89f3f618d1d5" />

```python
import pandas as pd
from gensim.corpora import Dictionary
from gensim.models import LdaModel, CoherenceModel

# âœ… ë°ì´í„° ë¡œë“œ
df = pd.read_csv("preprocessed_reviews.csv")

# âœ… tokens ì»¬ëŸ¼ ë³µì›

def parse_tokens(x):
    if pd.isna(x):
        return []
    if isinstance(x, str):
        try:
            return eval(x)
        except:
            return x.split()
    return x

tokens_list = df["tokens"].apply(parse_tokens).tolist()

# âœ… Dictionary / Corpus
dictionary = Dictionary(tokens_list)
corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]

# âœ… LDA í•™ìŠµ
num_topics = 5
lda_model = LdaModel(
    corpus=corpus,
    id2word=dictionary,
    num_topics=num_topics,
    random_state=42,
    passes=10
)

# âœ… í† í”½ ì¶œë ¥
for i, topic in lda_model.print_topics(num_words=8):
    print(f"Topic {i}: {topic}")

# âœ… Coherence í‰ê°€
coherence_model = CoherenceModel(
    model=lda_model,
    texts=tokens_list,
    dictionary=dictionary,
    coherence="c_v"
)
coherence_score = coherence_model.get_coherence()
print("Coherence Score:", round(coherence_score, 4))
```

</div>
</details>
```



